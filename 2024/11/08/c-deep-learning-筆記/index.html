<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/gg.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/gg.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/gg.png">
  <link rel="mask-icon" href="/images/gg.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-171640966-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-171640966-1');
</script>

<style>
    @font-face {
        /* font-family: "JasonHandwriting1-Regular"; */
/*
        src: url(https://cdn.jsdelivr.net/gh/max32002/JasonHandWritingFonts@20210716/webfont/JasonHandwriting1-Regular.woff2) format("woff2"), url(https://cdn.jsdelivr.net/gh/max32002/JasonHandWritingFonts@20210716/webfont/JasonHandwriting1-Regular.woff) format("woff");
		*/

        font-family: "俐方體11號";
        src: url(/fonts/Cubic_11_1.000_R.woff) format("woff")
    }
</style>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.blog.lasai.com.tw","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="&amp;nbsp;">
<meta property="og:type" content="article">
<meta property="og:title" content="c# deep learning 筆記">
<meta property="og:url" content="https://www.blog.lasai.com.tw/2024/11/08/c-deep-learning-%E7%AD%86%E8%A8%98/index.html">
<meta property="og:site_name" content="🌹 喇賽的人 Blog 🌹">
<meta property="og:description" content="&amp;nbsp;">
<meta property="og:locale" content="zh_TW">
<meta property="article:published_time" content="2024-11-08T04:30:44.000Z">
<meta property="article:modified_time" content="2025-03-06T04:43:47.462Z">
<meta property="article:author" content="🌹 喇賽人 🌹">
<meta property="article:tag" content="c#">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.blog.lasai.com.tw/2024/11/08/c-deep-learning-%E7%AD%86%E8%A8%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-TW'
  };
</script>

  <title>c# deep learning 筆記 | 🌹 喇賽的人 Blog 🌹</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-171640966-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-171640966-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  <!-- google ad -->
  <!--
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1069539516107706"
     crossorigin="anonymous"></script>
  -->
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!--
  <div class="spell" ></div>
  <div class="ghost" style="display: none;"></div>
  <div class="noise"></div>
  <div class="noise2"></div>
  -->


  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">🌹 喇賽的人 Blog 🌹</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">🌹 喇低喇賽 🌹</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>真喇賽</a>

  </li>
        <li class="menu-item menu-item-map">

    <a href="/map/" rel="section"><i class="fa fa-map fa-fw"></i>喇賽人的奇怪美食地圖</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>關於喇賽人</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>喇賽的標籤</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>喇賽亂寫</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://www.blog.lasai.com.tw/2024/11/08/c-deep-learning-%E7%AD%86%E8%A8%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="🌹 喇賽人 🌹">
      <meta itemprop="description" content="🌹 喇賽人的 Blog 🌹">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="🌹 喇賽的人 Blog 🌹">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          c# deep learning 筆記
        </h1>

        <div class="post-meta">
		
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">亂寫於</span>

              <time title="亂入時間：2024-11-08 12:30:44" itemprop="dateCreated datePublished" datetime="2024-11-08T12:30:44+08:00">2024-11-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-03-06 12:43:47" itemprop="dateModified" datetime="2025-03-06T12:43:47+08:00">2025-03-06</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2024/11/08/c-deep-learning-%E7%AD%86%E8%A8%98/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2024/11/08/c-deep-learning-筆記/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="廢話字數">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">廢話字數：</span>
              <span>43k</span>
            </span>
            <span class="post-meta-item" title="所需傷眼時間">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">所需傷眼時間 &asymp;</span>
              <span>39 分鐘</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>&nbsp;</p>
<a id="more"></a>

<p>因為練習 c 的關係, 看到有變態用 c 來手寫 Deep Learning, 就玩看看筆記下, 結果連程式碼都沒附真是狠, 希望不要太早陣亡 XD</p>
<h2 id="Single-Input-Single-Output-Neural-Network"><a href="#Single-Input-Single-Output-Neural-Network" class="headerlink" title="Single Input Single Output Neural Network"></a>Single Input Single Output Neural Network</h2><p>他第一個例子用天氣來預測 <code>開心</code> 或 <code>難過</code>, 非常簡單就是 溫度 * 權重 = 預測值</p>
<p>輸入 -&gt; 權重 -&gt; 輸出<br>input data -&gt; weight -&gt; output (predicted value)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">double temperature[] &#x3D; &#123;12, 23, 50, -10, 16&#125;;</span><br><span class="line">double weight &#x3D; -2;</span><br><span class="line"></span><br><span class="line">double single_in_single_out(double input, double weight)</span><br><span class="line">&#123;</span><br><span class="line">    double predicted &#x3D; input * weight;</span><br><span class="line">    return predicted;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;first value %f\n&quot;, single_in_single_out(temperature[0] , weight));</span><br><span class="line">    printf(&quot;second value %f\n&quot;, single_in_single_out(temperature[1] , weight));</span><br><span class="line">    printf(&quot;third value %f\n&quot;, single_in_single_out(temperature[2] , weight));</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c# 如下, 老生常談這裡一樣要先開 <code>&lt;AllowUnsafeBlocks&gt;True&lt;/AllowUnsafeBlocks&gt;</code> 這樣寫起來比較有趣</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">double[] temperature &#x3D; &#123;12, 23, 50, -10, 16&#125;;</span><br><span class="line">double weight &#x3D; -2;</span><br><span class="line"></span><br><span class="line">double SingleInSingleOut(double input, double weight)</span><br><span class="line">&#123;</span><br><span class="line">    double predicted &#x3D; input * weight;</span><br><span class="line">    return predicted;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Console.WriteLine(&quot;first value &#123;0&#125;&quot; , SingleInSingleOut(temperature[0] , weight));</span><br><span class="line">Console.WriteLine(&quot;second value &#123;0&#125;&quot; , SingleInSingleOut(temperature[1] , weight));</span><br><span class="line">Console.WriteLine(&quot;third value &#123;0&#125;&quot; , SingleInSingleOut(temperature[1] , weight));</span><br></pre></td></tr></table></figure>

<h2 id="Single-Input-Multiple-Output-Neural-Network"><a href="#Single-Input-Multiple-Output-Neural-Network" class="headerlink" title="Single Input Multiple Output Neural Network"></a>Single Input Multiple Output Neural Network</h2><p>假如我們知道這個人心情不太美麗, 我們能否計算 溫度 濕度 空氣品質?</p>
<p>Sad * 溫度權重<br>0.9 * -20</p>
<p>Sad * 濕度權重<br>0.9 * 95</p>
<p>Sad * 空氣品質權重<br>0.9 * 201</p>
<p>他程式碼裡的 input_scalar 即 Sad<br><code>Scalar 純量</code> 只有大小沒有方向的，如數量、距離、速度或溫度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">#define Sad 0.9</span><br><span class="line">#define TEMPERATURE_PREDICTION_IDX 0</span><br><span class="line">#define HUMIDITY_PREDICTION_IDX 1</span><br><span class="line">#define AIR_QUALITY_PREDICITION_IDX 2</span><br><span class="line"></span><br><span class="line">#define VECTOR_LEN 3</span><br><span class="line"></span><br><span class="line">double predicted_results[3];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;溫度權重 濕度權重 空氣品質權重</span><br><span class="line">double weights[3] &#x3D; &#123;-20 , 95 , 201&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;核心計算</span><br><span class="line">void elementwise_multiply(double input_scalar, double *weight_vector, double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        output_vector[i] &#x3D; input_scalar * weight_vector[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;包裝函數</span><br><span class="line">void single_in_multiple_out(double input_scalar, double *weight_vector, double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    elementwise_multiply(input_scalar, weight_vector, output_vector, LEN);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    single_in_multiple_out(Sad, weights, predicted_results , VECTOR_LEN);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F;預測值</span><br><span class="line">    printf(&quot;predicted temperature is: %f\n&quot;, predicted_results[TEMPERATURE_PREDICTION_IDX]);</span><br><span class="line">    printf(&quot;predicted humidity is: %f\n&quot;, predicted_results[HUMIDITY_PREDICTION_IDX]);</span><br><span class="line">    printf(&quot;predicted air quality is: %f\n&quot;, predicted_results[AIR_QUALITY_PREDICITION_IDX]);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c#</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    double Sad &#x3D; 0.9;</span><br><span class="line">    int TemperaturePrecictionIdx &#x3D; 0;</span><br><span class="line">    int HumidityPrecictionIdx &#x3D; 1;</span><br><span class="line">    int AirQualityPrecictionIdx &#x3D; 2;</span><br><span class="line">    int VectorLen &#x3D; 3;</span><br><span class="line"></span><br><span class="line">    double[] PredictedResults &#x3D; new double[3];</span><br><span class="line"></span><br><span class="line">    double[] weights &#x3D; &#123; -20, 95, 201 &#125;;</span><br><span class="line"></span><br><span class="line">    void ElementwiseMultiply(double input_scalar, double* weight_vector, double* output_vector, int LEN)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_vector[i] &#x3D; input_scalar * weight_vector[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void SingleInMultipleOut(double input_scalar, double* weight_vector, double* output_vector, int LEN)</span><br><span class="line">        &#x3D;&gt; ElementwiseMultiply(input_scalar, weight_vector, output_vector, LEN);</span><br><span class="line"></span><br><span class="line">    fixed (double* ptrWeights &#x3D; weights, ptrPredictedResults &#x3D; PredictedResults)</span><br><span class="line">    &#123;</span><br><span class="line">        SingleInMultipleOut(Sad, ptrWeights, ptrPredictedResults, VectorLen);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Console.WriteLine(&quot;predicted temperature is: &#123;0&#125;&quot;, PredictedResults[TemperaturePrecictionIdx]);</span><br><span class="line">    Console.WriteLine(&quot;predicted humidity is: &#123;0&#125;&quot;, PredictedResults[HumidityPrecictionIdx]);</span><br><span class="line">    Console.WriteLine(&quot;predicted air quality is: &#123;0&#125;&quot;, PredictedResults[AirQualityPrecictionIdx]);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Multiple-Input-Single-Output"><a href="#Multiple-Input-Single-Output" class="headerlink" title="Multiple Input Single Output"></a>Multiple Input Single Output</h2><p>(temperature * weight1) + (humidity * weight2) + (air qualtity * weight3) = Sad (預測值)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">&#x2F;&#x2F;特徵數量</span><br><span class="line">#define NUM_OF_INPUTS 3</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;計算加權總和</span><br><span class="line">double weighted_sum(double * input , double * weight, int LEN)&#123;</span><br><span class="line">	double output;</span><br><span class="line">	for(int i &#x3D;0 ; i &lt; LEN; i++)&#123;</span><br><span class="line">		output +&#x3D; input[i] * weight[i];</span><br><span class="line">	&#125;</span><br><span class="line">	return output;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;包裝函數</span><br><span class="line">double multiple_input_single_output(double * input , double * weight, int LEN)&#123;</span><br><span class="line">	double predicted_value;</span><br><span class="line">	</span><br><span class="line">	predicted_value &#x3D; weighted_sum( input , weight,  LEN);</span><br><span class="line">	return predicted_value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;溫度</span><br><span class="line">double temperature[] &#x3D; &#123;12,23,50,-10,16&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;濕度</span><br><span class="line">double humidity[] &#x3D; &#123;60,67,50,65,63&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;空氣品質</span><br><span class="line">double air_quality[] &#x3D; &#123;60,47,167,187,94&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;權重</span><br><span class="line">double weight[] &#x3D; &#123;-2,2,1&#125;;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">	double training_eg1[] &#x3D; &#123;temperature[0] , humidity[0],air_quality[0]&#125;;</span><br><span class="line">	printf(&quot;predcition from the traning example is: %f\r\n&quot;, multiple_input_single_output(training_eg1,weight,3));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c#</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line">    int NumOfInputs &#x3D; 3;</span><br><span class="line"></span><br><span class="line">    double WeightedSm(double* input, double* weight, int len)</span><br><span class="line">    &#123;</span><br><span class="line">        double output &#x3D; 0;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; len; i++)</span><br><span class="line">            output +&#x3D; input[i] * weight[i];</span><br><span class="line">        return output;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double MultipleInputSingleOutput(double* input, double* weight, int len)</span><br><span class="line">    &#123;</span><br><span class="line">        double predictedValue;</span><br><span class="line">        predictedValue &#x3D; WeightedSm(input, weight, len);</span><br><span class="line">        return predictedValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;溫度</span><br><span class="line">    double[] temperature &#x3D; &#123; 12, 23, 50, -10, 16 &#125;;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;濕度</span><br><span class="line">    double[] humidity &#x3D; &#123; 60, 67, 50, 65, 63 &#125;;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;空氣品質</span><br><span class="line">    double[] air_quality &#x3D; &#123; 60, 47, 167, 187, 94 &#125;;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;權重</span><br><span class="line">    double[] weight &#x3D; &#123; -2, 2, 1 &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    double[] training_eg1 &#x3D; &#123; temperature[0], humidity[0], air_quality[0] &#125;;</span><br><span class="line"></span><br><span class="line">    fixed (double* ptrWeight &#x3D; weight, ptrTrainingEg1 &#x3D; training_eg1)</span><br><span class="line">        Console.WriteLine(</span><br><span class="line">            &quot;predcition from the traning example is:&#123;0&#125;&quot;,</span><br><span class="line">            MultipleInputSingleOutput(ptrTrainingEg1, ptrWeight, 3)</span><br><span class="line">        );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Multiple-input-Multiple-output"><a href="#Multiple-input-Multiple-output" class="headerlink" title="Multiple input Multiple output"></a>Multiple input Multiple output</h2><p>這邊算法跟 Multiple Input Single Output 大同小異<br>只不過 output 變成三個, 這裡每一種 output 的 權重都不相同</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">		temperature		humidity	air quality</span><br><span class="line">SAD		-2				9.5			2.01</span><br><span class="line">SICK	-0.8			7.2			6.3</span><br><span class="line">ACTIVE	-0.5			0.45		0.9</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#define IN_LEN 3</span><br><span class="line">#define OUT_LEN 3</span><br><span class="line">#define SAD_PREDICTION_IDX 0</span><br><span class="line">#define SICK_PREDICTION_IDX 1</span><br><span class="line">#define ACTIVE_PREDICTION_IDX 2</span><br><span class="line"></span><br><span class="line">void matrix_vector_multiply(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    double *output_vector,</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double weight_matrix[OUTPUT_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k][i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void multiple_input_multiple_output_nn(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    double *output_vector,</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double weight_matrix[OUTPUT_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line">    matrix_vector_multiply(input_vector, INPUT_LEN, output_vector, OUTPUT_LEN, weight_matrix);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double predicted_results[3];</span><br><span class="line"></span><br><span class="line">double weights[OUT_LEN][IN_LEN] &#x3D; &#123;</span><br><span class="line">    &#123;-2, 9.5, 2.01&#125;,</span><br><span class="line">    &#123;-0.8, 7.2, 6.3&#125;,</span><br><span class="line">    &#123;-0.5, 0.45, 0.9&#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">double inputs[IN_LEN] &#x3D; &#123;30, 87, 110&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    multiple_input_multiple_output_nn(inputs , IN_LEN , predicted_results , OUT_LEN , weights);</span><br><span class="line"></span><br><span class="line">    printf(&quot;Sad prediction: %f \r\n&quot;, predicted_results[0]);</span><br><span class="line">    printf(&quot;Sick prediction: %f \r\n&quot;, predicted_results[1]);</span><br><span class="line">    printf(&quot;Active prediction: %f \r\n&quot;, predicted_results[2]);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c#</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line">    int IN_LEN &#x3D; 3;</span><br><span class="line">    int OUT_LEN &#x3D; 3;</span><br><span class="line">    int SAD_PREDICTION_IDX &#x3D; 0;</span><br><span class="line">    int SICK_PREDICTION_IDX &#x3D; 1;</span><br><span class="line">    int ACTIVE_PREDICTION_IDX &#x3D; 2;</span><br><span class="line"></span><br><span class="line">    void matrix_vector_multiply(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        double* output_vector,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] weight_matrix)</span><br><span class="line">    &#123;</span><br><span class="line"></span><br><span class="line">        for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k, i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void multiple_input_multiple_output_nn(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        double* output_vector,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] weight_matrix)</span><br><span class="line">    &#123;</span><br><span class="line">        matrix_vector_multiply(input_vector, INPUT_LEN, output_vector, OUTPUT_LEN, weight_matrix);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double[] predicted_results &#x3D; new double[3];</span><br><span class="line"></span><br><span class="line">    double[,] weights &#x3D; &#123;</span><br><span class="line">        &#123; -2, 9.5, 2.01&#125;,</span><br><span class="line">        &#123; -0.8, 7.2, 6.3&#125;,</span><br><span class="line">        &#123; -0.5, 0.45, 0.9&#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    double[] inputs &#x3D; &#123; 30, 87, 110 &#125;;</span><br><span class="line"></span><br><span class="line">    fixed (double* ptrInputs &#x3D; inputs, ptrPredictedResults &#x3D; predicted_results)</span><br><span class="line">    &#123;</span><br><span class="line">        multiple_input_multiple_output_nn(ptrInputs, IN_LEN, ptrPredictedResults, OUT_LEN, weights);</span><br><span class="line"></span><br><span class="line">        Console.WriteLine(&quot;Sad prediction: &#123;0&#125;&quot;, predicted_results[0]);</span><br><span class="line">        Console.WriteLine(&quot;Sick prediction: &#123;0&#125;&quot;, predicted_results[1]);</span><br><span class="line">        Console.WriteLine(&quot;Active prediction: &#123;0&#125;&quot;, predicted_results[2]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="hidden-layer"><a href="#hidden-layer" class="headerlink" title="hidden layer"></a>hidden layer</h2><p>由 Multiple input Multiple output 延伸, 只不過中間卡一層隱藏層, 先算出隱藏層數值後, 然後再去做一次加權運算最後得到輸出值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">			temperature		humidity	air quality</span><br><span class="line">hidden[0]			-2			9.5				2.01</span><br><span class="line">hidden[1]			-0.8		7.2				6.3</span><br><span class="line">hidden[2]			-0.5		0.45			0.9</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">		hidden[0]	hidden[1]	hidden[2]</span><br><span class="line">SAD			-1			1.15		0.11</span><br><span class="line">SICK		-0.18		0.15		-0.01</span><br><span class="line">ACTIVE		0.25		-0.25		-0.1</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">#define IN_LEN 3</span><br><span class="line">#define OUT_LEN 3</span><br><span class="line">#define HID_LEN 3</span><br><span class="line"></span><br><span class="line">void matrix_vector_multiply(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    double *output_vector,</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double weight_matrix[OUTPUT_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k][i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double hidden_pred_vector[HID_LEN];</span><br><span class="line"></span><br><span class="line">void hidden_layer_nn(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    int HIDDEN_LEN,</span><br><span class="line">    double in_to_hid_weights[HIDDEN_LEN][INPUT_LEN],</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double hid_to_out_weights[OUTPUT_LEN][HIDDEN_LEN],</span><br><span class="line">    double *output_vector)</span><br><span class="line">&#123;</span><br><span class="line">    matrix_vector_multiply(input_vector, INPUT_LEN, hidden_pred_vector, OUTPUT_LEN, in_to_hid_weights);</span><br><span class="line">    matrix_vector_multiply(hidden_pred_vector, HIDDEN_LEN, output_vector, OUTPUT_LEN, hid_to_out_weights);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double predicted_results[3];</span><br><span class="line"></span><br><span class="line">double input_to_hidden_weights[HID_LEN][IN_LEN] &#x3D; &#123;</span><br><span class="line">    &#123;-2, 9.5, 2.01&#125;,</span><br><span class="line">    &#123;-0.8, 7.2, 6.3&#125;,</span><br><span class="line">    &#123;-0.5, 0.45, 0.9&#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">double hidden_to_output_weights[OUT_LEN][IN_LEN] &#x3D; &#123;</span><br><span class="line">    &#123;-1, 1.15, 0.11&#125;,</span><br><span class="line">    &#123;-0.18, 0.15, -0.01&#125;,</span><br><span class="line">    &#123;0.25, -0.25, -0.1&#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">double inputs[IN_LEN] &#x3D; &#123;30, 87, 110&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    hidden_layer_nn(inputs, IN_LEN, HID_LEN, input_to_hidden_weights, OUT_LEN, hidden_to_output_weights, predicted_results);</span><br><span class="line">    printf(&quot;Sad prediction: %f \r\n&quot;, predicted_results[0]);</span><br><span class="line">    printf(&quot;Sick prediction: %f \r\n&quot;, predicted_results[1]);</span><br><span class="line">    printf(&quot;Active prediction: %f \r\n&quot;, predicted_results[2]);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c#</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line">    int IN_LEN &#x3D; 3;</span><br><span class="line">    int OUT_LEN &#x3D; 3;</span><br><span class="line">    int HID_LEN &#x3D; 3;</span><br><span class="line"></span><br><span class="line">    void matrix_vector_multiply(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        double* output_vector,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] weight_matrix)</span><br><span class="line">    &#123;</span><br><span class="line"></span><br><span class="line">        for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k, i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    double[] hidden_pred_vector &#x3D; new double[HID_LEN];</span><br><span class="line"></span><br><span class="line">    void hidden_layer_nn(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        int HIDDEN_LEN,</span><br><span class="line">        double[,] in_to_hid_weights,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] hid_to_out_weights,</span><br><span class="line">        double* output_vector)</span><br><span class="line">    &#123;</span><br><span class="line">        fixed (double* ptrHiddenPredVector &#x3D; hidden_pred_vector)</span><br><span class="line">        &#123;</span><br><span class="line">            matrix_vector_multiply(input_vector, INPUT_LEN, ptrHiddenPredVector, OUTPUT_LEN, in_to_hid_weights);</span><br><span class="line">            matrix_vector_multiply(ptrHiddenPredVector, HIDDEN_LEN, output_vector, OUTPUT_LEN, hid_to_out_weights);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double[] predicted_results &#x3D; new double[3];</span><br><span class="line"></span><br><span class="line">    double[,] input_to_hidden_weights &#x3D; &#123;</span><br><span class="line">        &#123; -2, 9.5, 2.01&#125;,</span><br><span class="line">        &#123; -0.8, 7.2, 6.3&#125;,</span><br><span class="line">        &#123; -0.5, 0.45, 0.9&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    double[,] hidden_to_output_weights &#x3D; &#123;</span><br><span class="line">        &#123; -1, 1.15, 0.11&#125;,</span><br><span class="line">        &#123; -0.18, 0.15, -0.01&#125;,</span><br><span class="line">        &#123; 0.25, -0.25, -0.1&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    double[] inputs &#x3D; &#123; 30, 87, 110 &#125;;</span><br><span class="line">    fixed (double* ptrInputs &#x3D; inputs , ptrPredictedResults &#x3D; predicted_results)</span><br><span class="line">    &#123;</span><br><span class="line">        hidden_layer_nn(ptrInputs, IN_LEN, HID_LEN, input_to_hidden_weights, OUT_LEN, hidden_to_output_weights, ptrPredictedResults);</span><br><span class="line">        Console.WriteLine(&quot;Sad prediction: &#123;0&#125;&quot;, predicted_results[0]);</span><br><span class="line">        Console.WriteLine(&quot;Sick prediction: &#123;0&#125;&quot;, predicted_results[1]);</span><br><span class="line">        Console.WriteLine(&quot;Active prediction: &#123;0&#125;&quot;, predicted_results[2]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="finding-error"><a href="#finding-error" class="headerlink" title="finding error"></a>finding error</h2><p>predicted_value = input * weight<br>error = power(predicted_value - expected_value)</p>
<p>weight = 0.8<br>expected_value = 26<br>input = 25</p>
<p>predicted_value = 25 * 0.8<br>error = power( 20 - 26 )<br>error = 36</p>
<p>實作新增兩隻函數</p>
<p><code>double find_error(double input, double weight, double expected_value)</code></p>
<p><code>double find_error_simple(double yhat, double y)</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;math.h&gt;</span><br><span class="line"></span><br><span class="line">#define IN_LEN 3</span><br><span class="line">#define OUT_LEN 3</span><br><span class="line">#define HID_LEN 3</span><br><span class="line"></span><br><span class="line">void matrix_vector_multiply(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    double *output_vector,</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double weight_matrix[OUTPUT_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k][i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double hidden_pred_vector[HID_LEN];</span><br><span class="line"></span><br><span class="line">void hidden_layer_nn(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    int HIDDEN_LEN,</span><br><span class="line">    double in_to_hid_weights[HIDDEN_LEN][INPUT_LEN],</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double hid_to_out_weights[OUTPUT_LEN][HIDDEN_LEN],</span><br><span class="line">    double *output_vector)</span><br><span class="line">&#123;</span><br><span class="line">    matrix_vector_multiply(input_vector, INPUT_LEN, hidden_pred_vector, OUTPUT_LEN, in_to_hid_weights);</span><br><span class="line">    matrix_vector_multiply(hidden_pred_vector, HIDDEN_LEN, output_vector, OUTPUT_LEN, hid_to_out_weights);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double find_error(double input, double weight, double expected_value)</span><br><span class="line">&#123;</span><br><span class="line">    return powf(((input * weight) - expected_value), 2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double find_error_simple(double yhat, double y)</span><br><span class="line">&#123;</span><br><span class="line">    return powf((yhat - y), 2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double predicted_results[3];</span><br><span class="line"></span><br><span class="line">double input_to_hidden_weights[HID_LEN][IN_LEN] &#x3D; &#123;</span><br><span class="line">    &#123;-2, 9.5, 2.01&#125;,</span><br><span class="line">    &#123;-0.8, 7.2, 6.3&#125;,</span><br><span class="line">    &#123;-0.5, 0.45, 0.9&#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">double hidden_to_output_weights[OUT_LEN][IN_LEN] &#x3D; &#123;</span><br><span class="line">    &#123;-1, 1.15, 0.11&#125;,</span><br><span class="line">    &#123;-0.18, 0.15, -0.01&#125;,</span><br><span class="line">    &#123;0.25, -0.25, -0.1&#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">double inputs[IN_LEN] &#x3D; &#123;30, 87, 110&#125;;</span><br><span class="line"></span><br><span class="line">double expected_values[OUT_LEN] &#x3D; &#123;600, 10, -90&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    hidden_layer_nn(inputs, IN_LEN, HID_LEN, input_to_hidden_weights, OUT_LEN, hidden_to_output_weights, predicted_results);</span><br><span class="line">    printf(&quot;Sad prediction: %f \r\n&quot;, predicted_results[0]);</span><br><span class="line">    printf(&quot;Sad Error: %f \r\n&quot;, find_error_simple(predicted_results[0], expected_values[0]));</span><br><span class="line">    printf(&quot;Sick prediction: %f \r\n&quot;, predicted_results[1]);</span><br><span class="line">    printf(&quot;Sick Error: %f \r\n&quot;, find_error_simple(predicted_results[1], expected_values[1]));</span><br><span class="line">    printf(&quot;Active prediction: %f \r\n&quot;, predicted_results[2]);</span><br><span class="line">    printf(&quot;Active Error: %f \r\n&quot;, find_error_simple(predicted_results[2], expected_values[2]));</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c#</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line">    int IN_LEN &#x3D; 3;</span><br><span class="line">    int OUT_LEN &#x3D; 3;</span><br><span class="line">    int HID_LEN &#x3D; 3;</span><br><span class="line"></span><br><span class="line">    void matrix_vector_multiply(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        double* output_vector,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] weight_matrix)</span><br><span class="line">    &#123;</span><br><span class="line"></span><br><span class="line">        for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k, i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    double[] hidden_pred_vector &#x3D; new double[HID_LEN];</span><br><span class="line"></span><br><span class="line">    void hidden_layer_nn(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        int HIDDEN_LEN,</span><br><span class="line">        double[,] in_to_hid_weights,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] hid_to_out_weights,</span><br><span class="line">        double* output_vector)</span><br><span class="line">    &#123;</span><br><span class="line">        fixed (double* ptrHiddenPredVector &#x3D; hidden_pred_vector)</span><br><span class="line">        &#123;</span><br><span class="line">            matrix_vector_multiply(input_vector, INPUT_LEN, ptrHiddenPredVector, OUTPUT_LEN, in_to_hid_weights);</span><br><span class="line">            matrix_vector_multiply(ptrHiddenPredVector, HIDDEN_LEN, output_vector, OUTPUT_LEN, hid_to_out_weights);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double find_error(double input, double weight, double expected_value)</span><br><span class="line">    &#123;</span><br><span class="line">        return Math.Pow(((input * weight) - expected_value), 2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double find_error_simple(double yhat, double y)</span><br><span class="line">    &#123;</span><br><span class="line">        return Math.Pow((yhat - y), 2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void brute_force_learning(</span><br><span class="line">        double input,</span><br><span class="line">        double weight,</span><br><span class="line">        double expected_value,</span><br><span class="line">        double step_amount,</span><br><span class="line">        int itr)</span><br><span class="line">    &#123;</span><br><span class="line">        double preciction, error;</span><br><span class="line">        double up_prediction;</span><br><span class="line">        double up_error;</span><br><span class="line">        double down_prediction;</span><br><span class="line">        double down_error;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; itr; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            preciction &#x3D; input * weight;</span><br><span class="line">            error &#x3D; Math.Pow((preciction - expected_value), 2);</span><br><span class="line">            Console.WriteLine(&quot;Error : &#123;0&#125; Prediction : &#123;1&#125; \r\n&quot;, error, preciction);</span><br><span class="line"></span><br><span class="line">            up_prediction &#x3D; input * (weight + step_amount);</span><br><span class="line">            up_error &#x3D; Math.Pow((expected_value - up_prediction), 2);</span><br><span class="line"></span><br><span class="line">            down_prediction &#x3D; input * (weight - step_amount);</span><br><span class="line">            down_error &#x3D; Math.Pow((expected_value - down_prediction), 2);</span><br><span class="line"></span><br><span class="line">            if (down_error &lt; up_error)</span><br><span class="line">                weight &#x3D; weight - step_amount;</span><br><span class="line">            if (down_error &gt; up_error)</span><br><span class="line">                weight &#x3D; weight + step_amount;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double[] predicted_results &#x3D; new double[3];</span><br><span class="line"></span><br><span class="line">    double[,] input_to_hidden_weights &#x3D; &#123;</span><br><span class="line">        &#123; -2, 9.5, 2.01&#125;,</span><br><span class="line">        &#123; -0.8, 7.2, 6.3&#125;,</span><br><span class="line">        &#123; -0.5, 0.45, 0.9&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    double[,] hidden_to_output_weights &#x3D; &#123;</span><br><span class="line">        &#123; -1, 1.15, 0.11&#125;,</span><br><span class="line">        &#123; -0.18, 0.15, -0.01&#125;,</span><br><span class="line">        &#123; 0.25, -0.25, -0.1&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    double[] expected_values &#x3D; &#123; 600, 10, -90 &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    double[] inputs &#x3D; &#123; 30, 87, 110 &#125;;</span><br><span class="line">    fixed (double* ptrInputs &#x3D; inputs, ptrPredictedResults &#x3D; predicted_results)</span><br><span class="line">    &#123;</span><br><span class="line">        hidden_layer_nn(ptrInputs, IN_LEN, HID_LEN, input_to_hidden_weights, OUT_LEN, hidden_to_output_weights, ptrPredictedResults);</span><br><span class="line">        Console.WriteLine(&quot;Sad prediction: &#123;0&#125;&quot;, predicted_results[0]);</span><br><span class="line">        Console.WriteLine(&quot;Sad Error: %f \r\n&quot;, find_error_simple(predicted_results[0], expected_values[0]));</span><br><span class="line"></span><br><span class="line">        Console.WriteLine(&quot;Sick prediction: &#123;0&#125;&quot;, predicted_results[1]);</span><br><span class="line">        Console.WriteLine(&quot;Sick prediction: %f \r\n&quot;, find_error_simple(predicted_results[1], expected_values[1]));</span><br><span class="line"></span><br><span class="line">        Console.WriteLine(&quot;Active prediction: &#123;0&#125;&quot;, predicted_results[2]);</span><br><span class="line">        Console.WriteLine(&quot;Active prediction: %f \r\n&quot;, find_error_simple(predicted_results[2], expected_values[2]));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="暴力學習"><a href="#暴力學習" class="headerlink" title="暴力學習"></a>暴力學習</h2><p>這感覺有點像是猜數字遊戲, 反正沒猜中就調整數值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;math.h&gt;</span><br><span class="line"></span><br><span class="line">void brute_force_learning(</span><br><span class="line">    double input,</span><br><span class="line">    double weight,</span><br><span class="line">    double expected_value,</span><br><span class="line">    double step_amount,</span><br><span class="line">    int itr)</span><br><span class="line">&#123;</span><br><span class="line">    double preciction, error;</span><br><span class="line">    double up_prediction;</span><br><span class="line">    double up_error;</span><br><span class="line">    double down_prediction;</span><br><span class="line">    double down_error;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; itr; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        preciction &#x3D; input * weight;</span><br><span class="line">        error &#x3D; powf((preciction - expected_value),2);</span><br><span class="line">        printf(&quot;Error : %f Prediction : %f \r\n&quot;, error, preciction);</span><br><span class="line"></span><br><span class="line">        up_prediction &#x3D; input * (weight + step_amount);</span><br><span class="line">        up_error &#x3D; powf((expected_value - up_prediction), 2);</span><br><span class="line"></span><br><span class="line">        down_prediction &#x3D; input * (weight - step_amount);</span><br><span class="line">        down_error &#x3D; powf((expected_value - down_prediction), 2);</span><br><span class="line"></span><br><span class="line">        if (down_error &lt; up_error)</span><br><span class="line">            weight &#x3D; weight - step_amount;</span><br><span class="line">        if (down_error &gt; up_error)</span><br><span class="line">            weight &#x3D; weight + step_amount;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double weight &#x3D; 0.5;</span><br><span class="line">double input &#x3D; 0.5;</span><br><span class="line">double expected_value &#x3D; 0.8;</span><br><span class="line">double step_amount &#x3D; 0.001;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    brute_force_learning(input , weight , expected_value , step_amount , 1200);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>這裡在 c# 比較難搞, 因為 c# 用 double 會造成精度損失, 所以型別要改用 decimal 提高精度<br>這裡可以先看下實驗, 他會輸出 0.1999999999998181</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">double a &#x3D; 5000.2, b &#x3D; 5000;</span><br><span class="line">double c &#x3D; a - b;</span><br><span class="line">Console.WriteLine(c);</span><br><span class="line">&#x2F;&#x2F;輸出 0.1999999999998181</span><br></pre></td></tr></table></figure>

<p>另外 c# 的 Math.Pow 不支援 decimal, 所以只能自己算<br>或是這裡沿用 double 然後用 Math.Round 取個小數 8 ~ 10 位</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">decimal weight &#x3D; 0.5m;</span><br><span class="line">decimal input &#x3D; 0.5m;</span><br><span class="line">decimal expected_value &#x3D; 0.8m;</span><br><span class="line">decimal step_amount &#x3D; 0.001m;</span><br><span class="line"></span><br><span class="line">void brute_force_learning(</span><br><span class="line">    decimal input,</span><br><span class="line">    decimal weight,</span><br><span class="line">    decimal expected_value,</span><br><span class="line">    decimal step_amount,</span><br><span class="line">    int itr)</span><br><span class="line">&#123;</span><br><span class="line">    decimal preciction, error;</span><br><span class="line">    decimal up_prediction;</span><br><span class="line">    decimal up_error;</span><br><span class="line">    decimal down_prediction;</span><br><span class="line">    decimal down_error;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; itr; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        preciction &#x3D; input * weight;</span><br><span class="line">        error &#x3D; (preciction - expected_value) * (preciction - expected_value);</span><br><span class="line">        Console.WriteLine(&quot;Error : &#123;0&#125; Prediction : &#123;1&#125; \r\n&quot;, error, preciction);</span><br><span class="line"></span><br><span class="line">        up_prediction &#x3D; input * (weight + step_amount);</span><br><span class="line">        up_error &#x3D; (expected_value - up_prediction) * (expected_value - up_prediction);</span><br><span class="line"></span><br><span class="line">        down_prediction &#x3D; input * (weight - step_amount);</span><br><span class="line">        down_error &#x3D; (expected_value - down_prediction) * (expected_value - down_prediction);</span><br><span class="line"></span><br><span class="line">        if (down_error &lt; up_error)</span><br><span class="line">            weight &#x3D; weight - step_amount;</span><br><span class="line">        if (down_error &gt; up_error)</span><br><span class="line">            weight &#x3D; weight + step_amount;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">brute_force_learning(input, weight, expected_value, step_amount, 1200);</span><br></pre></td></tr></table></figure>

<h2 id="Normalizing-DataSets"><a href="#Normalizing-DataSets" class="headerlink" title="Normalizing DataSets"></a>Normalizing DataSets</h2><p>他這裡比較簡單, 就把每個 array 裡面的最大值撈出來, 接著每個 array 的 element 除最大值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;math.h&gt;</span><br><span class="line">#define NUM_OF_FEATURES 2 &#x2F;&#x2F; n values</span><br><span class="line">#define NUM_OF_EXAMPLES 3 &#x2F;&#x2F; m values</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Hours of workout</span><br><span class="line">double x1[NUM_OF_EXAMPLES] &#x3D; &#123;2, 5, 1&#125;;</span><br><span class="line">double _x1[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Hours of rest data</span><br><span class="line">double x2[NUM_OF_EXAMPLES] &#x3D; &#123;8, 5, 8&#125;;</span><br><span class="line">double _x2[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Muscle gain data</span><br><span class="line">double y[NUM_OF_EXAMPLES] &#x3D; &#123;200, 90, 190&#125;;</span><br><span class="line">double _y[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void normalize_data(double *input_vector, double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    int i;</span><br><span class="line">    double max &#x3D; input_vector[0];</span><br><span class="line">    for (i &#x3D; 1; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        if (input_vector[i] &gt; max)</span><br><span class="line">        &#123;</span><br><span class="line">            max &#x3D; input_vector[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 正規化</span><br><span class="line">    for (i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        output_vector[i] &#x3D; input_vector[i] &#x2F; max;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    normalize_data(x1, _x1, NUM_OF_EXAMPLES);</span><br><span class="line">    normalize_data(x2, _x2, NUM_OF_EXAMPLES);</span><br><span class="line">    normalize_data(y, _y, NUM_OF_EXAMPLES);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    printf(&quot;Raw x1 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot; %f &quot;, x1[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    printf(&quot;Normalized _x1 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot; %f &quot;, _x1[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    printf(&quot;Raw x2 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot; %f &quot;, x2[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    printf(&quot;Normalized _x2 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot; %f &quot;, _x2[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    printf(&quot;Raw y data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot; %f &quot;, y[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    printf(&quot;Normalized _y data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot; %f &quot;, y[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c# 如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line">    int NUM_OF_FEATURES &#x3D; 2;</span><br><span class="line">    int NUM_OF_EXAMPLES &#x3D; 3;</span><br><span class="line"></span><br><span class="line">    double[] x1 &#x3D; &#123; 2, 5, 1 &#125;;</span><br><span class="line">    double[] _x1 &#x3D; new double[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">    double[] x2 &#x3D; &#123; 8, 5, 8 &#125;;</span><br><span class="line">    double[] _x2 &#x3D; new double[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">    double[] y &#x3D; &#123; 200, 90, 190 &#125;;</span><br><span class="line">    double[] _y &#x3D; new double[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">    void normalize_data(double* input_vector, double* output_vector, int LEN)</span><br><span class="line">    &#123;</span><br><span class="line">        int i;</span><br><span class="line">        double max &#x3D; input_vector[0];</span><br><span class="line">        for (i &#x3D; 1; i &lt; LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            if (input_vector[i] &gt; max)</span><br><span class="line">            &#123;</span><br><span class="line">                max &#x3D; input_vector[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 正規化</span><br><span class="line">        for (i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_vector[i] &#x3D; input_vector[i] &#x2F; max;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fixed (double* ptrX1 &#x3D; x1, _ptrX1 &#x3D; _x1, ptrX2 &#x3D; x2, _ptrX2 &#x3D; _x2, ptrY &#x3D; y, _ptrY &#x3D; _y)</span><br><span class="line">    &#123;</span><br><span class="line">        normalize_data(ptrX1, _ptrX1, NUM_OF_EXAMPLES);</span><br><span class="line">        normalize_data(ptrX2, _ptrX2, NUM_OF_EXAMPLES);</span><br><span class="line">        normalize_data(ptrY, _ptrY, NUM_OF_EXAMPLES);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Console.Write(&quot;Raw x1 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(&quot; &#123;0&#125; &quot;, x1[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    Console.Write(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    Console.Write(&quot;Normalized _x1 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(&quot; &#123;0&#125; &quot;, _x1[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    Console.Write(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Console.Write(&quot;Raw x2 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(&quot; &#123;0&#125; &quot;, x2[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    Console.Write(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    Console.Write(&quot;Normalized _x2 data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(&quot; &#123;0&#125; &quot;, _x2[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    Console.Write(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Console.Write(&quot;Raw y data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(&quot; &#123;0&#125; &quot;, y[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    Console.Write(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    Console.Write(&quot;Normalized _y data: \r\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_EXAMPLES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(&quot; &#123;0&#125; &quot;, y[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    Console.Write(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Random-Initialzation-of-Weights"><a href="#Random-Initialzation-of-Weights" class="headerlink" title="Random Initialzation of Weights"></a>Random Initialzation of Weights</h2><p><code>Synapse 突觸</code> 神經元之間，或神經元與肌細胞、腺體之間通信的特異性接頭</p>
<p>他這裡用兩個特徵 <code>hours of work out</code> <code>hours of rest data</code> 當作範例, 中間有三個隱藏的 <code>node</code> 最後有一個輸出<br>然後跑亂數, 最後得到權重 (Synapse)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">synapse 0 weight:</span><br><span class="line">0.500000  0.600000 </span><br><span class="line"></span><br><span class="line">0.800000  0.500000</span><br><span class="line"></span><br><span class="line">0.400000  0.000000</span><br><span class="line"></span><br><span class="line">synapse 1 weight:</span><br><span class="line">0.500000  0.600000  0.800000</span><br></pre></td></tr></table></figure>

<p>c 程式碼</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;math.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;特徵數量</span><br><span class="line">#define NUM_OF_FEATURES 2 &#x2F;&#x2F; n values</span><br><span class="line">&#x2F;&#x2F;範例資料筆數</span><br><span class="line">#define NUM_OF_EXAMPLES 3 &#x2F;&#x2F; m values</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;隱藏層節點</span><br><span class="line">#define NUM_OF_HID_NODES 3</span><br><span class="line">&#x2F;&#x2F;輸出節點</span><br><span class="line">#define NUM_OF_OUT_NODES 1</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Hours of workout</span><br><span class="line">double x1[NUM_OF_EXAMPLES] &#x3D; &#123;2, 5, 1&#125;;</span><br><span class="line">double _x1[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Hours of rest data</span><br><span class="line">double x2[NUM_OF_EXAMPLES] &#x3D; &#123;8, 5, 8&#125;;</span><br><span class="line">double _x2[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Muscle gain data</span><br><span class="line">double y[NUM_OF_EXAMPLES] &#x3D; &#123;200, 90, 190&#125;;</span><br><span class="line">double _y[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">void normalize_data(double *input_vector, double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    int i;</span><br><span class="line">    double max &#x3D; input_vector[0];</span><br><span class="line">    for (i &#x3D; 1; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        if (input_vector[i] &gt; max)</span><br><span class="line">        &#123;</span><br><span class="line">            max &#x3D; input_vector[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 正規化</span><br><span class="line">    for (i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        output_vector[i] &#x3D; input_vector[i] &#x2F; max;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void weight_random_initialization(int HIDDEN_LEN, int INPUT_LEN, double weights_matrix[HIDDEN_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line">    srand(2);</span><br><span class="line">    double d_rand;</span><br><span class="line"></span><br><span class="line">    for (int i &#x3D; 0; i &lt; HIDDEN_LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j &#x3D; 0; j &lt; INPUT_LEN; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            d_rand &#x3D; (rand() % 10);</span><br><span class="line">            d_rand &#x2F;&#x3D; 10;</span><br><span class="line"></span><br><span class="line">            weights_matrix[i][j] &#x3D; d_rand;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;input layer to hidden layer weights buffer</span><br><span class="line">double syn0[NUM_OF_HID_NODES][NUM_OF_FEATURES];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;hidden layer to output layer weights buffer</span><br><span class="line">double syn1[NUM_OF_OUT_NODES][NUM_OF_HID_NODES];</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    weight_random_initialization(NUM_OF_HID_NODES, NUM_OF_FEATURES , syn0);</span><br><span class="line">    weight_random_initialization(NUM_OF_OUT_NODES, NUM_OF_HID_NODES , syn1);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;synapse 0 weight</span><br><span class="line">    printf(&quot;synapse 0 weight:\n&quot;);</span><br><span class="line">    for(int i &#x3D;0 ; i &lt; NUM_OF_HID_NODES; i ++) &#123;</span><br><span class="line">        for(int j &#x3D; 0 ; j &lt; NUM_OF_FEATURES ; j++)&#123;</span><br><span class="line">            printf(&quot; %f &quot;, syn0[i][j]);</span><br><span class="line">        &#125;</span><br><span class="line">        printf(&quot;\n\r&quot;);</span><br><span class="line">        printf(&quot;\n\r&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;synapse 1 weight</span><br><span class="line">    printf(&quot;synapse 1 weight:\n&quot;);</span><br><span class="line">    for(int i &#x3D;0 ; i &lt; NUM_OF_OUT_NODES; i ++) &#123;</span><br><span class="line">        for(int j &#x3D; 0 ; j &lt; NUM_OF_HID_NODES ; j++)&#123;</span><br><span class="line">            printf(&quot; %f &quot;, syn1[i][j]);</span><br><span class="line">        &#125;</span><br><span class="line">        printf(&quot;\n\r&quot;);</span><br><span class="line">        printf(&quot;\n\r&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c# 如下</p>
<p>這裡唯一不同應該是撈亂數的方法, c 的 rand() 會撈 0 ~ 32767, 在 c# 可以用 Next(0,32767) 來指定</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line">    int NUM_OF_FEATURES &#x3D; 2;</span><br><span class="line">    int NUM_OF_EXAMPLES &#x3D; 3;</span><br><span class="line">    int NUM_OF_HID_NODES &#x3D; 3;</span><br><span class="line">    int NUM_OF_OUT_NODES &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    double[] x1 &#x3D; &#123; 2, 5, 1 &#125;;</span><br><span class="line">    double[] _x1 &#x3D; new double[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">    double[] x2 &#x3D; &#123; 8, 5, 8 &#125;;</span><br><span class="line">    double[] _x2 &#x3D; new double[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">    double[] y &#x3D; &#123; 200, 90, 190 &#125;;</span><br><span class="line">    double[] _y &#x3D; new double[NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">    void weight_random_initialization(int HIDDEN_LEN, int INPUT_LEN, double[,] weights_matrix)</span><br><span class="line">    &#123;</span><br><span class="line">        double d_rand;</span><br><span class="line">        var rnd &#x3D; new Random();</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; HIDDEN_LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int j &#x3D; 0; j &lt; INPUT_LEN; j++)</span><br><span class="line">            &#123;</span><br><span class="line">                d_rand &#x3D; (rnd.Next(0 , 32767) % 10);</span><br><span class="line">                d_rand &#x2F;&#x3D; 10;</span><br><span class="line"></span><br><span class="line">                weights_matrix[i, j] &#x3D; d_rand;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;input layer to hidden layer weights buffer</span><br><span class="line">    double[,] syn0 &#x3D; new double[NUM_OF_HID_NODES, NUM_OF_FEATURES];</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;hidden layer to output layer weights buffer</span><br><span class="line">    double[,] syn1 &#x3D; new double[NUM_OF_OUT_NODES, NUM_OF_HID_NODES];</span><br><span class="line"></span><br><span class="line">    weight_random_initialization(NUM_OF_HID_NODES, NUM_OF_FEATURES, syn0);</span><br><span class="line">    weight_random_initialization(NUM_OF_OUT_NODES, NUM_OF_HID_NODES, syn1);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;synapse 0 weight</span><br><span class="line">    Console.Write(&quot;synapse 0 weight:\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_HID_NODES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j &#x3D; 0; j &lt; NUM_OF_FEATURES; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            Console.Write(&quot; &#123;0&#125; &quot;, syn0[i, j]);</span><br><span class="line">        &#125;</span><br><span class="line">        Console.Write(&quot;\n\r&quot;);</span><br><span class="line">        Console.Write(&quot;\n\r&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;synapse 1 weight</span><br><span class="line">    Console.Write(&quot;synapse 1 weight:\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_OUT_NODES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j &#x3D; 0; j &lt; NUM_OF_HID_NODES; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            Console.Write(&quot; &#123;0&#125; &quot;, syn1[i, j]);</span><br><span class="line">        &#125;</span><br><span class="line">        Console.Write(&quot;\n\r&quot;);</span><br><span class="line">        Console.Write(&quot;\n\r&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Forward-Propagation"><a href="#Forward-Propagation" class="headerlink" title="Forward Propagation"></a>Forward Propagation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;math.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 特徵數量</span><br><span class="line">#define NUM_OF_FEATURES 2 &#x2F;&#x2F; n values</span><br><span class="line">&#x2F;&#x2F; 範例資料筆數</span><br><span class="line">#define NUM_OF_EXAMPLES 3 &#x2F;&#x2F; m values</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 隱藏層節點</span><br><span class="line">#define NUM_OF_HID_NODES 3</span><br><span class="line">&#x2F;&#x2F; 輸出節點</span><br><span class="line">#define NUM_OF_OUT_NODES 1</span><br><span class="line"></span><br><span class="line">void normalize_data(double *input_vector, double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    int i;</span><br><span class="line">    double max &#x3D; input_vector[0];</span><br><span class="line">    for (i &#x3D; 1; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        if (input_vector[i] &gt; max)</span><br><span class="line">        &#123;</span><br><span class="line">            max &#x3D; input_vector[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 正規化</span><br><span class="line">    for (i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        output_vector[i] &#x3D; input_vector[i] &#x2F; max;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void weight_random_initialization(int HIDDEN_LEN, int INPUT_LEN, double weights_matrix[HIDDEN_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line">    srand(2);</span><br><span class="line">    double d_rand;</span><br><span class="line"></span><br><span class="line">    for (int i &#x3D; 0; i &lt; HIDDEN_LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j &#x3D; 0; j &lt; INPUT_LEN; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            d_rand &#x3D; (rand() % 10);</span><br><span class="line">            d_rand &#x2F;&#x3D; 10;</span><br><span class="line"></span><br><span class="line">            weights_matrix[i][j] &#x3D; d_rand;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void normalize_data_2d(int ROW, int COL, double input_matrix[ROW][COL], double output_matrix[ROW][COL])</span><br><span class="line">&#123;</span><br><span class="line">    double max &#x3D; -999999;</span><br><span class="line">    for (int y &#x3D; 0; y &lt; ROW; y++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int x &#x3D; 0; x &lt; COL; x++)</span><br><span class="line">        &#123;</span><br><span class="line">            if (input_matrix[y][x] &gt; max)</span><br><span class="line">                max &#x3D; input_matrix[y][x];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (int y &#x3D; 0; y &lt; ROW; y++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int x &#x3D; 0; x &lt; COL; x++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_matrix[y][x] &#x3D; input_matrix[y][x] &#x2F; max;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void weight_random_initialzation_1d(double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    double d_rand;</span><br><span class="line">    srand(2);</span><br><span class="line">    for (int j &#x3D; 0; j &lt; LEN; j++)</span><br><span class="line">    &#123;</span><br><span class="line">        d_rand &#x3D; (rand() % 10);</span><br><span class="line">        d_rand &#x2F;&#x3D; 10;</span><br><span class="line">        output_vector[j] &#x3D; d_rand;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void matrix_vector_multiply(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    double *output_vector,</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double weight_matrix[OUTPUT_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k][i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 計算加權總和</span><br><span class="line">double weighted_sum(double *input, double *weight, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    double output;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        output +&#x3D; input[i] * weight[i];</span><br><span class="line">    &#125;</span><br><span class="line">    return output;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 包裝函數</span><br><span class="line">double multiple_input_single_output(double *input, double *weight, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    double predicted_value;</span><br><span class="line"></span><br><span class="line">    predicted_value &#x3D; weighted_sum(input, weight, LEN);</span><br><span class="line">    return predicted_value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void multiple_input_multiple_output_nn(</span><br><span class="line">    double *input_vector,</span><br><span class="line">    int INPUT_LEN,</span><br><span class="line">    double *output_vector,</span><br><span class="line">    int OUTPUT_LEN,</span><br><span class="line">    double weight_matrix[OUTPUT_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line">    matrix_vector_multiply(input_vector, INPUT_LEN, output_vector, OUTPUT_LEN, weight_matrix);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double sigmoid(double x)</span><br><span class="line">&#123;</span><br><span class="line">    double result &#x3D; 1 &#x2F; (1 + exp(-x));</span><br><span class="line">    return result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void vector_sigmoid(double *input_vector, double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">        output_vector[i] &#x3D; sigmoid(input_vector[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double raw_x[NUM_OF_FEATURES][NUM_OF_EXAMPLES] &#x3D; &#123;</span><br><span class="line">    &#123;2, 5, 1&#125;,</span><br><span class="line">    &#123;8, 5, 8&#125;&#125;;</span><br><span class="line"></span><br><span class="line">double raw_y[1][NUM_OF_EXAMPLES] &#x3D; &#123;&#123;200, 90, 190&#125;&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;* Train x</span><br><span class="line">   2&#x2F;8 5&#x2F;8 1&#x2F;8</span><br><span class="line">   8&#x2F;8 5&#x2F;8 8&#x2F;8</span><br><span class="line">   dim &#x3D; nx X m</span><br><span class="line"> *&#x2F;</span><br><span class="line">double train_x[NUM_OF_FEATURES][NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">&#x2F;* Train y</span><br><span class="line">   200&#x2F;200 90&#x2F;200 190&#x2F;200</span><br><span class="line"> *&#x2F;</span><br><span class="line">double train_y[1][NUM_OF_EXAMPLES];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; input layer to hidden layer weights buffer</span><br><span class="line">double syn0[NUM_OF_HID_NODES][NUM_OF_FEATURES];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; hidden layer to output layer weights buffer</span><br><span class="line">double syn1[NUM_OF_OUT_NODES][NUM_OF_HID_NODES];</span><br><span class="line"></span><br><span class="line">double train_x_eg1[NUM_OF_FEATURES];</span><br><span class="line">double train_y_eg1;</span><br><span class="line">double z1_eg1[NUM_OF_HID_NODES];</span><br><span class="line">double a1_eg1[NUM_OF_HID_NODES];</span><br><span class="line">double z2_eg1;</span><br><span class="line">double yhat_eg1;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    normalize_data_2d(NUM_OF_FEATURES, NUM_OF_EXAMPLES, raw_x, train_x);</span><br><span class="line">    normalize_data_2d(1, NUM_OF_EXAMPLES, raw_y, train_y);</span><br><span class="line"></span><br><span class="line">    train_x_eg1[0] &#x3D; train_x[0][0];</span><br><span class="line">    train_x_eg1[1] &#x3D; train_x[1][0];</span><br><span class="line"></span><br><span class="line">    train_y_eg1 &#x3D; train_y[0][0];</span><br><span class="line"></span><br><span class="line">    printf(&quot;train_x_eg1 is [%f %f]&quot;, train_x_eg1[0], train_x_eg1[1]);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    printf(&quot;train_y_eg1 is %f&quot;, train_y_eg1);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    weight_random_initialization(NUM_OF_HID_NODES, NUM_OF_FEATURES, syn0);</span><br><span class="line">    &#x2F;&#x2F; weight_random_initialization(NUM_OF_OUT_NODES, NUM_OF_HID_NODES, syn1);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; synapse 0 weight</span><br><span class="line">    printf(&quot;synapse 0 weight:\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_HID_NODES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j &#x3D; 0; j &lt; NUM_OF_FEATURES; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            printf(&quot; %f &quot;, syn0[i][j]);</span><br><span class="line">        &#125;</span><br><span class="line">        printf(&quot;\n\r&quot;);</span><br><span class="line">        printf(&quot;\n\r&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    weight_random_initialzation_1d(syn1, NUM_OF_OUT_NODES);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_OUT_NODES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot;synapse 1 [%f %f %f]&quot;, syn1[0], syn1[1], syn1[2]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; z1</span><br><span class="line">    multiple_input_multiple_output_nn(train_x_eg1, NUM_OF_FEATURES, z1_eg1, NUM_OF_HID_NODES, syn0);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    printf(&quot; z_eg1 &#x3D; [%f %f %f]&quot;, z1_eg1[0], z1_eg1[1], z1_eg1[2]);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; a1</span><br><span class="line">    vector_sigmoid(z1_eg1, a1_eg1, NUM_OF_HID_NODES);</span><br><span class="line">    printf(&quot; a_eg1 &#x3D; [%f %f %f]&quot;, a1_eg1[0], a1_eg1[1], a1_eg1[2]);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    z2_eg1 &#x3D; multiple_input_single_output(a1_eg1 , syn1 , NUM_OF_HID_NODES);</span><br><span class="line">    printf(&quot;z2_eg1 : %f&quot;, z2_eg1);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;yhat</span><br><span class="line">    yhat_eg1 &#x3D; sigmoid(z2_eg1);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    printf(&quot;yhat_eg1 : %f&quot;, yhat_eg1);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line">    printf(&quot;\n\r&quot;);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>這裡先新增 <code>normalize_data_2d</code> 函數, 先取 matrix 內的最大值, 接著 loop 每個數值 / max 即可</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">void normalize_data_2d(int ROW, int COL, double input_matrix[ROW][COL], double output_matrix[ROW][COL])</span><br><span class="line">&#123;</span><br><span class="line">    double max &#x3D; -999999;</span><br><span class="line">    for (int y &#x3D; 0; y &lt; ROW; y++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int x &#x3D; 0; x &lt; COL; x++)</span><br><span class="line">        &#123;</span><br><span class="line">            if (input_matrix[y][x] &gt; max)</span><br><span class="line">                max &#x3D; input_matrix[y][x];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (int y &#x3D; 0; y &lt; ROW; y++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int x &#x3D; 0; x &lt; COL; x++)</span><br><span class="line">        &#123;</span><br><span class="line">            output_matrix[y][x] &#x3D; input_matrix[y][x] &#x2F; max;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然後宣告 <code>2(高 NUM_OF_FEATURES) * 3(寬 NUM_OF_EXAMPLES)</code> 的 raw_x 變數, 接著讓他正規化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">double raw_x[NUM_OF_FEATURES][NUM_OF_EXAMPLES] &#x3D; &#123;</span><br><span class="line">    &#123;2, 5, 1&#125;,</span><br><span class="line">    &#123;8, 5, 8&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">2&#x2F;8 5&#x2F;8 1&#x2F;8</span><br><span class="line">8&#x2F;8 5&#x2F;8 8&#x2F;8</span><br><span class="line"></span><br><span class="line">0.250000 0.625000 0.125000</span><br><span class="line">1.000000 0.625000 1.000000</span><br><span class="line">*&#x2F;</span><br><span class="line">double train_x[NUM_OF_FEATURES][NUM_OF_EXAMPLES];</span><br></pre></td></tr></table></figure>

<p>接著宣告 <code>1(高) * 3(寬 NUM_OF_EXAMPLES)</code> 的 raw_y 變數, 呼叫正規化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">double raw_y[1][NUM_OF_EXAMPLES] &#x3D; &#123;</span><br><span class="line">	&#123;200, 90, 190&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;* </span><br><span class="line">200&#x2F;200 90&#x2F;200 190&#x2F;200</span><br><span class="line"></span><br><span class="line">1.000000 0.450000 0.950000</span><br><span class="line">*&#x2F;</span><br><span class="line">double train_y[1][NUM_OF_EXAMPLES];</span><br></pre></td></tr></table></figure>

<p>接續定義函數 <code>weight_random_initialization</code><br>他會隨機取得 0 ~ 9 之間的數字, 最後 /10 會得到 0.x 塞入 2d array 內<br>最後就可以獲得亂數 0.0 ~ 0.9 的權重<br><code>weight_random_initialzation_1d</code> 也是類似效果, 只不過換種寫法適用 1d array</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">void weight_random_initialization(int HIDDEN_LEN, int INPUT_LEN, double weights_matrix[HIDDEN_LEN][INPUT_LEN])</span><br><span class="line">&#123;</span><br><span class="line">    srand(2);</span><br><span class="line">    double d_rand;</span><br><span class="line"></span><br><span class="line">    for (int i &#x3D; 0; i &lt; HIDDEN_LEN; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j &#x3D; 0; j &lt; INPUT_LEN; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            d_rand &#x3D; (rand() % 10);</span><br><span class="line">            d_rand &#x2F;&#x3D; 10;</span><br><span class="line"></span><br><span class="line">            weights_matrix[i][j] &#x3D; d_rand;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接著呼叫之前寫過的函數 <code>multiple_input_multiple_output_nn</code><br>train_x_eg1 =&gt; input<br>syn0 =&gt; 輸入層到隱藏層的權重矩陣<br>計算隱藏層的加權總和 z1_eg1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">multiple_input_multiple_output_nn(train_x_eg1, NUM_OF_FEATURES, z1_eg1, NUM_OF_HID_NODES, syn0);</span><br></pre></td></tr></table></figure>

<p>然後定義激活函數 <code>sigmoid</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">double sigmoid(double x)</span><br><span class="line">&#123;</span><br><span class="line">    double result &#x3D; 1 &#x2F; (1 + exp(-x));</span><br><span class="line">    return result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void vector_sigmoid(double *input_vector, double *output_vector, int LEN)</span><br><span class="line">&#123;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">        output_vector[i] &#x3D; sigmoid(input_vector[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以激活函數算出隱藏層的輸出 a1_eg1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector_sigmoid(z1_eg1, a1_eg1, NUM_OF_HID_NODES);</span><br></pre></td></tr></table></figure>

<p>以 <code>multiple_input_single_output</code> 算出輸出層的加權總和 z2_eg1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z2_eg1 &#x3D; multiple_input_single_output(a1_eg1, syn1, NUM_OF_HID_NODES);</span><br></pre></td></tr></table></figure>

<p>以激活函數算出最終值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yhat_eg1 &#x3D; sigmoid(z2_eg1);</span><br></pre></td></tr></table></figure>

<p>他的 c# 如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><span class="line">unsafe</span><br><span class="line">&#123;</span><br><span class="line">    int NUM_OF_FEATURES &#x3D; 2;</span><br><span class="line">    int NUM_OF_EXAMPLES &#x3D; 3;</span><br><span class="line">    int NUM_OF_HID_NODES &#x3D; 3;</span><br><span class="line">    int NUM_OF_OUT_NODES &#x3D; 1;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    void weight_random_initialization(int HIDDEN_LEN, int INPUT_LEN, double[,] weights_matrix)</span><br><span class="line">    &#123;</span><br><span class="line">        Random random &#x3D; new Random();</span><br><span class="line">        double d_rand;</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; HIDDEN_LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int j &#x3D; 0; j &lt; INPUT_LEN; j++)</span><br><span class="line">            &#123;</span><br><span class="line">                &#x2F;&#x2F;d_rand &#x3D; (rand() % 10);</span><br><span class="line">                d_rand &#x3D; random.Next(0, 9);</span><br><span class="line">                d_rand &#x2F;&#x3D; 10;</span><br><span class="line"></span><br><span class="line">                weights_matrix[i, j] &#x3D; d_rand;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void weight_random_initialzation_1d(double* output_vector, int LEN)</span><br><span class="line">    &#123;</span><br><span class="line">        double d_rand;</span><br><span class="line">        Random random &#x3D; new Random();</span><br><span class="line">        &#x2F;&#x2F;srand(2);</span><br><span class="line">        for (int j &#x3D; 0; j &lt; LEN; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            d_rand &#x3D; random.Next(0, 9);</span><br><span class="line">            &#x2F;&#x2F;d_rand &#x3D; (rand() % 10);</span><br><span class="line">            d_rand &#x2F;&#x3D; 10;</span><br><span class="line">            output_vector[j] &#x3D; d_rand;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void matrix_vector_multiply(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        double* output_vector,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] weight_matrix)</span><br><span class="line">    &#123;</span><br><span class="line"></span><br><span class="line">        for (int k &#x3D; 0; k &lt; OUTPUT_LEN; k++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int i &#x3D; 0; i &lt; INPUT_LEN; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                output_vector[k] +&#x3D; input_vector[i] * weight_matrix[k, i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void multiple_input_multiple_output_nn(</span><br><span class="line">        double* input_vector,</span><br><span class="line">        int INPUT_LEN,</span><br><span class="line">        double* output_vector,</span><br><span class="line">        int OUTPUT_LEN,</span><br><span class="line">        double[,] weight_matrix)</span><br><span class="line">    &#123;</span><br><span class="line">        matrix_vector_multiply(input_vector, INPUT_LEN, output_vector, OUTPUT_LEN, weight_matrix);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    double sigmoid(double x)</span><br><span class="line">    &#123;</span><br><span class="line">        double result &#x3D; 1 &#x2F; (1 + Math.Exp(-x));</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void vector_sigmoid(double* input_vector, double* output_vector, int LEN)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">            output_vector[i] &#x3D; sigmoid(input_vector[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    void normalize_data_2d(int ROW, int COL, double[,] input_matrix, double[,] output_matrix)</span><br><span class="line">    &#123;</span><br><span class="line">        double max &#x3D; -999999;</span><br><span class="line">        for (int y &#x3D; 0; y &lt; ROW; y++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int x &#x3D; 0; x &lt; COL; x++)</span><br><span class="line">            &#123;</span><br><span class="line">                if (input_matrix[y, x] &gt; max)</span><br><span class="line">                    max &#x3D; input_matrix[y, x];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        for (int y &#x3D; 0; y &lt; ROW; y++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int x &#x3D; 0; x &lt; COL; x++)</span><br><span class="line">            &#123;</span><br><span class="line">                output_matrix[y, x] &#x3D; input_matrix[y, x] &#x2F; max;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 計算加權總和</span><br><span class="line">    double weighted_sum(double* input, double* weight, int LEN)</span><br><span class="line">    &#123;</span><br><span class="line">        double output &#x3D; 0;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; LEN; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            output +&#x3D; input[i] * weight[i];</span><br><span class="line">        &#125;</span><br><span class="line">        return output;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 包裝函數</span><br><span class="line">    double multiple_input_single_output(double* input, double* weight, int LEN)</span><br><span class="line">    &#123;</span><br><span class="line">        double predicted_value;</span><br><span class="line"></span><br><span class="line">        predicted_value &#x3D; weighted_sum(input, weight, LEN);</span><br><span class="line">        return predicted_value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;input layer to hidden layer weights buffer</span><br><span class="line">    double[,] syn0 &#x3D; new double[NUM_OF_HID_NODES, NUM_OF_FEATURES];</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;hidden layer to output layer weights buffer</span><br><span class="line">    double[,] syn1 &#x3D; new double[NUM_OF_OUT_NODES, NUM_OF_HID_NODES];</span><br><span class="line"></span><br><span class="line">    double[] train_x_eg1 &#x3D; new double[NUM_OF_FEATURES];</span><br><span class="line">    double train_y_eg1;</span><br><span class="line">    double[] z1_eg1 &#x3D; new double[NUM_OF_HID_NODES];</span><br><span class="line">    double[] a1_eg1 &#x3D; new double[NUM_OF_HID_NODES];</span><br><span class="line">    double z2_eg1;</span><br><span class="line">    double yhat_eg1;</span><br><span class="line"></span><br><span class="line">    double[,] raw_x &#x3D; &#123;</span><br><span class="line">        &#123;2, 5, 1&#125;,</span><br><span class="line">        &#123;8, 5, 8&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    double[,] train_x &#x3D; new double[2, 3];</span><br><span class="line">    double[,] raw_y &#x3D; &#123;</span><br><span class="line">        &#123;200, 90, 190&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    double[,] train_y &#x3D; new double[1, 3];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    normalize_data_2d(NUM_OF_FEATURES, NUM_OF_EXAMPLES, raw_x, train_x);</span><br><span class="line">    normalize_data_2d(1, NUM_OF_EXAMPLES, raw_y, train_y);</span><br><span class="line"></span><br><span class="line">    train_x_eg1[0] &#x3D; train_x[0, 0];</span><br><span class="line">    train_x_eg1[1] &#x3D; train_x[1, 0];</span><br><span class="line"></span><br><span class="line">    train_y_eg1 &#x3D; train_y[0, 0];</span><br><span class="line"></span><br><span class="line">    Console.WriteLine(&quot;train_x_eg1 is [&#123;0&#125; &#123;1&#125;]&quot;, train_x_eg1[0], train_x_eg1[1]);</span><br><span class="line"></span><br><span class="line">    Console.WriteLine(&quot;train_y_eg1 is &#123;0&#125;&quot;, train_y_eg1);</span><br><span class="line"></span><br><span class="line">    weight_random_initialization(NUM_OF_HID_NODES, NUM_OF_FEATURES, syn0);</span><br><span class="line">    &#x2F;&#x2F; weight_random_initialization(NUM_OF_OUT_NODES, NUM_OF_HID_NODES, syn1);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; synapse 0 weight</span><br><span class="line">    Console.WriteLine(&quot;synapse 0 weight:\n&quot;);</span><br><span class="line">    for (int i &#x3D; 0; i &lt; NUM_OF_HID_NODES; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j &#x3D; 0; j &lt; NUM_OF_FEATURES; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            Console.Write(&quot; &#123;0&#125; &quot;, syn0[i, j]);</span><br><span class="line">        &#125;</span><br><span class="line">        Console.WriteLine();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fixed (double* ptrSyn1 &#x3D; syn1)</span><br><span class="line">    &#123;</span><br><span class="line">        weight_random_initialzation_1d(ptrSyn1, NUM_OF_OUT_NODES);</span><br><span class="line">        &#x2F;&#x2F;weight_random_initialzation_1d(syn1, NUM_OF_OUT_NODES);</span><br><span class="line">        Console.WriteLine(&quot;\n\r&quot;);</span><br><span class="line">        for (int i &#x3D; 0; i &lt; NUM_OF_OUT_NODES; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            &#x2F;&#x2F;Console.Write(&quot;synapse 1 [%f %f %f]&quot;, syn1[0], syn1[1], syn1[2]);</span><br><span class="line">            Console.Write(&quot;synapse 1 [&#123;0&#125; &#123;1&#125; &#123;2&#125;]&quot;, syn1[0, 0], syn1[0, 1], syn1[0, 2]);</span><br><span class="line">        &#125;</span><br><span class="line">        Console.WriteLine();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; z1</span><br><span class="line">    fixed (double* ptrTrainXEg1 &#x3D; train_x_eg1, ptrZ1Eg1 &#x3D; z1_eg1, ptrA1Eg1 &#x3D; a1_eg1, ptrSyn1 &#x3D; syn1)</span><br><span class="line">    &#123;</span><br><span class="line">        multiple_input_multiple_output_nn(ptrTrainXEg1, NUM_OF_FEATURES, ptrZ1Eg1, NUM_OF_HID_NODES, syn0);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;multiple_input_multiple_output_nn(train_x_eg1, NUM_OF_FEATURES, z1_eg1, NUM_OF_HID_NODES, syn0);</span><br><span class="line">        Console.WriteLine();</span><br><span class="line">        Console.WriteLine();</span><br><span class="line"></span><br><span class="line">        Console.WriteLine(&quot; z_eg1 &#x3D; [&#123;0&#125; &#123;1&#125; &#123;2&#125;]&quot;, z1_eg1[0], z1_eg1[1], z1_eg1[2]);</span><br><span class="line">        Console.WriteLine();</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; a1</span><br><span class="line">        &#x2F;&#x2F;vector_sigmoid(z1_eg1, a1_eg1, NUM_OF_HID_NODES);</span><br><span class="line">        vector_sigmoid(ptrZ1Eg1, ptrA1Eg1, NUM_OF_HID_NODES);</span><br><span class="line">        Console.WriteLine(&quot; a_eg1 &#x3D; [&#123;0&#125; &#123;1&#125; &#123;2&#125;]&quot;, a1_eg1[0], a1_eg1[1], a1_eg1[2]);</span><br><span class="line"></span><br><span class="line">        z2_eg1 &#x3D; multiple_input_single_output(ptrA1Eg1, ptrSyn1, NUM_OF_HID_NODES);</span><br><span class="line">        Console.WriteLine(&quot;z2_eg1 : &#123;0&#125;&quot;, z2_eg1);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;yhat</span><br><span class="line">        yhat_eg1 &#x3D; sigmoid(z2_eg1);</span><br><span class="line">        Console.WriteLine();</span><br><span class="line"></span><br><span class="line">        Console.WriteLine(&quot;yhat_eg1 : &#123;0&#125;&quot;, yhat_eg1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/c/" rel="tag"># c#</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/11/07/angular-%E4%B8%B2%E6%8E%A5-prismjs-%E7%AD%86%E8%A8%98/" rel="prev" title="angular 串接 prismjs 筆記">
      <i class="fa fa-chevron-left"></i> angular 串接 prismjs 筆記
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/11/15/chrome-%E5%91%BC%E5%8F%AB-web-api-%E5%9B%9E%E5%82%B3-xml-%E4%B9%8B%E8%AC%8E/" rel="next" title="chrome 呼叫 web api 回傳 xml 之謎">
      chrome 呼叫 web api 回傳 xml 之謎 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Single-Input-Single-Output-Neural-Network"><span class="nav-number">1.</span> <span class="nav-text">Single Input Single Output Neural Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Single-Input-Multiple-Output-Neural-Network"><span class="nav-number">2.</span> <span class="nav-text">Single Input Multiple Output Neural Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multiple-Input-Single-Output"><span class="nav-number">3.</span> <span class="nav-text">Multiple Input Single Output</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multiple-input-Multiple-output"><span class="nav-number">4.</span> <span class="nav-text">Multiple input Multiple output</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hidden-layer"><span class="nav-number">5.</span> <span class="nav-text">hidden layer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#finding-error"><span class="nav-number">6.</span> <span class="nav-text">finding error</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#暴力學習"><span class="nav-number">7.</span> <span class="nav-text">暴力學習</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Normalizing-DataSets"><span class="nav-number">8.</span> <span class="nav-text">Normalizing DataSets</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Random-Initialzation-of-Weights"><span class="nav-number">9.</span> <span class="nav-text">Random Initialzation of Weights</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Forward-Propagation"><span class="nav-number">10.</span> <span class="nav-text">Forward Propagation</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="🌹 喇賽人 🌹"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">🌹 喇賽人 🌹</p>
  <div class="site-description" itemprop="description">🌹 喇賽人的 Blog 🌹</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">309</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">118</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/weber87na" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;weber87na" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

	  <!-- skilltree 廣告 -->
	  <div id="myadblock" style="margin-top:25px;position:relative">
	  <div id="myadblock-title" style="position:absolute;left:-10px;top:-10px;width:100px;background-color:rgba(0,0,0,.75);color:white;">偷放工商</div>
	  <script src="https://skilltree.my/promotion/cec9b4b0-be5e-4727-85c6-f7af5445124a?w=350"></script>
	  </div>

	  <!-- google 廣告 -->
	  <!--
	  <ins class="adsbygoogle"
		  style="display:inline-block;width:220px;height:120px;margin-top:50px;position:relative;border-bottom-left-radius: 15px 255px;border-bottom-right-radius: 225px 15px;border-top-left-radius: 255px 15px;border-top-right-radius: 15px 225px;border: 2px solid #41403e;"
		  data-ad-client="ca-pub-1069539516107706"
		  data-ad-slot="6588270137">
	  <div id="myadblock-title2" style="z-index:999999;position:absolute;left:-10px;top:-10px;width:100px;background-color:rgba(0,0,0,.75);color:white;">偷放工商</div>
	  </ins>
	  <script>
		  (adsbygoogle = window.adsbygoogle || []).push({});
	  </script>
	  -->

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">喇賽的人! G__G+</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">總廢話字數：</span>
    <span title="總廢話字數">1.6m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">所需總浪費時間 &asymp;</span>
    <span title="所需總浪費時間">24:26</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://la-sai-de-ren.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://www.blog.lasai.com.tw/2024/11/08/c-deep-learning-%E7%AD%86%E8%A8%98/";
    this.page.identifier = "2024/11/08/c-deep-learning-筆記/";
    this.page.title = "c# deep learning 筆記";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://la-sai-de-ren.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>


  <!-- <div class="snow1" style="position:fixed !important"></div> -->
  <div class="cobweb" style="position:fixed !important"></div>
  <div class="spider" style="position:fixed !important"></div>
<div class="fswitch">關閉</div>
<div class="snowflakes" aria-hidden="true">
  <div class="snowflake">
 🌹
  </div>
  <div class="snowflake">
 💩
  </div>
  <div class="snowflake">
 🌹
  </div>
  <div class="snowflake">
 💩
  </div>
    <div class="snowflake">
 🌹
  </div>
  <div class="snowflake">
 💩
  </div>
    <div class="snowflake">
 🌹
  </div>
  <div class="snowflake">
 💩
  </div>
</div>

<!--
<script>
	function toggleSpell() {
		let spell = document.getElementsByClassName('spell')[0];
		let ghost = document.getElementsByClassName('ghost')[0];
		let noise = document.getElementsByClassName('noise')[0];
		let noise2 = document.getElementsByClassName('noise2')[0];
		if (spell.style.display === 'none') {
			spell.style.display = 'block';
			noise.style.display = '';
			noise2.style.display = '';
			ghost.style.display = 'none';
		} else {
			spell.style.display = 'none';
			noise.style.display = 'none';
			noise2.style.display = 'none';
			ghost.style.display = 'block';
		}
	}

	//訂閱內容
	let spell = document.getElementsByClassName('spell')[0];
	let ghost = document.getElementsByClassName('ghost')[0];
	spell.addEventListener('click',toggleSpell);
	ghost.addEventListener('click',toggleSpell);
</script>
-->

<script>

let cobweb = document.querySelector('.cobweb');
let spider = document.querySelector('.spider');
let back = document.querySelector('.back-to-top');
let fswitch = document.querySelector('.fswitch');

document.addEventListener('keydown', function(event) {
	if (event.key === 'f') {
		console.log('press f key');
		ftoggle();
	}
});

fswitch.addEventListener('click' , function(){ 
	ftoggle();
});

function ftoggle(){
	if(cobweb.style.display === ''){
		cobweb.style.display = 'none';
	}else{
		cobweb.style.display = '';
	}
	if(spider.style.display === ''){
		spider.style.display = 'none';
	}else{
		spider.style.display = '';
	}
	if(back.style.display === ''){
		back.style.display = 'none';
	}else{
		back.style.display = '';
	}

	if(fswitch.innerText === '關閉') fswitch.innerText = '乖乖'
	else fswitch.innerText = '關閉'
}



</script>

<script>
class ViNavigation {
  constructor() {
    this.Mode = {
      Normal: "normal",
      Motion: "motion",
    };

    this.lastKeyPressTime = 0;
    this.lastKeyPressed = "";
    this.currentMode = this.Mode.Normal;

    //可使用移動的字碼
    //共 18 個字 排除 vi 會用到的字
    this.tagChars = "ABCEILNOPQRSTVWXYZ";

    //目前的 vim 標示字標籤 array
    this.holdTags = new Array();

    //預先建立兩字組合的字典
    this.dict = new Array();
    //雙層迴圈灌入所有兩字組合
    for (var i = 0; i < this.tagChars.length; i++) {
      for (var j = 0; j < this.tagChars.length; j++) {
        this.dict.push(this.tagChars[i] + this.tagChars[j]);
      }
    }
  }

  viGoTop(keyPressed) {
    if (keyPressed === "g") {
      window.scrollTo({ top: 0, behavior: "smooth" });
    }
  }

  viGoBottom(keyPressed) {
    if (keyPressed === "G") {
      console.log("document.body.scrollHeight", document.body.scrollHeight);
      let h = Math.max(
        Math.max(
          document.body.scrollHeight,
          document.documentElement.scrollHeight
        ),
        Math.max(
          document.body.offsetHeight,
          document.documentElement.offsetHeight
        ),
        Math.max(
          document.body.clientHeight,
          document.documentElement.clientHeight
        )
      );
      window.scrollTo({ top: h, behavior: "smooth" });
    }
  }

  viFastDown(keyPressed) {
    if (keyPressed === "d") {
      this.move(350);
    }
  }

  viDown(keyPressed) {
    if (keyPressed === "j") {
      this.move(100);
    }
  }

  viFastUp(keyPressed) {
    if (keyPressed === "u") {
      this.move(-350);
    }
  }

  viUp(keyPressed) {
    if (keyPressed === "k") {
      this.move(-100);
    }
  }

  move(val) {
    var currentPosition =
      window.pageYOffset || document.documentElement.scrollTop;
    window.scrollTo({
      top: currentPosition + val,
      behavior: "smooth",
    });
  }

  removeViTags() {
    let allTags = document.querySelectorAll(".vim-tag");
    allTags.forEach(function (tag) {
      tag.parentNode.removeChild(tag);
    });
  }

  createViTag(text, href, top, left) {
    let newDiv = document.createElement("div");
    newDiv.classList.add("vim-tag");
    newDiv.style.fontFamily = "Arial, sans-serif";
    newDiv.style.fontSize = "12px";
    newDiv.style.position = "absolute";
    newDiv.style.backgroundColor = "#89CF07";
    newDiv.style.color = "black";
    newDiv.style.padding = "2px";
    newDiv.style.borderRadius = "2px";
    newDiv.style.zIndex = "999999";

    newDiv.textContent = text;
    newDiv.dataset.href = href;
    newDiv.style.top = top;
    newDiv.style.left = left;
    return newDiv;
  }

  createViTags() {
    let allTags = document.querySelectorAll("a");
    let counter = 0;
    for (let tag of allTags) {
      let rect = tag.getBoundingClientRect();
      let href = tag.href;
      //這個距離需要加入卷軸距離才會正確
      let top = window.scrollY + rect.top + "px";
      let left = window.scrollX + rect.left + "px";
      let text = "";
      if (allTags.length <= this.tagChars.length) {
        text = this.tagChars[counter];
        this.holdTags.push(text);
      } else {
        text = this.dict[counter];
        this.holdTags.push(text);
      }
      let newDiv = this.createViTag(text, href, top, left);
      document.body.appendChild(newDiv);
      counter++;
    }
  }

  //找出目前的首字 array
  firstCharArray() {
    let result = [];
    for (let i = 0; i < this.holdTags.length; i++) {
      let text = this.holdTags[i];
      if (text) {
        let theChar = text[0].toLowerCase();
        if (result.includes(theChar) === false) {
          result.push(theChar);
        }
      }
    }

    return result;
  }

  toggleMotion() {
    this.currentMode = this.Mode.Motion;
    this.lastKeyPressed = "";
    console.log("mode", this.currentMode);
    this.createViTags();
  }

  toggleNormal() {
    this.currentMode = this.Mode.Normal;
    console.log("mode", this.currentMode);
    this.removeViTags();
    this.holdTags = [];
    this.lastKeyPressed = "";
  }

  handleKeyDown(event) {
    let currentTime = new Date().getTime();
    let keyPressed = event.key;

    //按下 F 時進入 motion 模式
    if (this.currentMode === this.Mode.Normal && keyPressed === "F") {
      this.toggleMotion();
      return;
    }

    //按下 esc 跳離 motion 模式回到 normal 模式
    if (this.currentMode === this.Mode.Motion && keyPressed === "Escape") {
      this.toggleNormal();
      return;
    }

    //當 motion 一個字時才走這模式
    if (
      this.currentMode === this.Mode.Motion &&
      document.querySelectorAll("a").length <= this.tagChars.length &&
      this.tagChars.toLowerCase().includes(keyPressed)
    ) {
      console.log("one char mode");
      let allTags = document.querySelectorAll(".vim-tag");

      allTags.forEach(function (tag) {
        if (tag.textContent.toLowerCase() === keyPressed) {
          window.location.href = tag.dataset.href;
        }
      });

      this.toggleNormal();
      return;
    }

    //當 motion 兩個字才走這個模式
    if (
      this.currentMode === this.Mode.Motion &&
      document.querySelectorAll("a").length > this.tagChars.length
    ) {
      console.log("motion lastKeyPressed", this.lastKeyPressed);
      console.log("motion current", keyPressed);

      if (!this.lastKeyPressed) {
        //如果出現字表以外的字則回到 normal
        //console.log("firstCharArray", this.firstCharArray());
        if (this.firstCharArray().includes(keyPressed) === false) {
          this.toggleNormal();
          return;
        } else {
          let allTags = document.querySelectorAll(".vim-tag");
          allTags.forEach(function (tag) {
            if (tag.textContent[0].toLowerCase() !== keyPressed) {
              tag.parentNode.removeChild(tag);
            }

            //將第一個字變為紅色
            if (tag.textContent[0].toLowerCase() === keyPressed) {
              tag.innerHTML =
                '<span style="color: red;">' +
                tag.textContent.charAt(0) +
                "</span>" +
                tag.textContent.substring(1);
            }
          });
        }
      }

      //如果有字的話才執行
      if (this.lastKeyPressed) {
        let chars = this.lastKeyPressed + keyPressed;
        console.log("chars", chars);
        let allTags = document.querySelectorAll(".vim-tag");
        allTags.forEach(function (tag) {
          if (tag.textContent.toLowerCase() === chars) {
            window.location.href = tag.dataset.href;
          }
        });
        //萬一沒找到切回 Normal
        this.toggleNormal();
        return;
      }
    }

    // 任何模式按兩下的區域
    if (
      keyPressed === this.lastKeyPressed &&
      currentTime - this.lastKeyPressTime < 300
    ) {
      this.viGoTop(keyPressed);
    }

    // 按一下的區域
    this.viGoBottom(keyPressed);
    this.viDown(keyPressed);
    this.viFastDown(keyPressed);
    this.viUp(keyPressed);
    this.viFastUp(keyPressed);

    this.lastKeyPressTime = currentTime;
    this.lastKeyPressed = keyPressed;
  }

  init() {
    document.addEventListener("keydown", this.handleKeyDown.bind(this));
  }
}

const viNavigation = new ViNavigation();
viNavigation.init();
</script>



</body>
</html>
